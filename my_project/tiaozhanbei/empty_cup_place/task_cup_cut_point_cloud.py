#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time : 2025/10/25
# @Author : ZhangXi

import os
import time
import cv2
import numpy as np
import time
from sklearn.cluster import DBSCAN
import wrs.basis.robot_math as rm
from my_project.tiaozhanbei.empty_cup_place.constant import YOLO_MODEL_CUPS_PATH, CUP_MODEL_PATH, GRASP_PATH_CUPS,  \
    MIDDLE_CAM_C2W, LEFT_HAND_EYE, RIGHT_HAND_EYE
from wrs import wd, rm, mgm, mcm, ppp, gg, gpa
import wrs.modeling.geometric_model as gm
from wrs.robot_sim.robots.piper.piper_dual_arm import DualPiperNoBody
from wrs.robot_con.piper.piper import PiperArmController
import wrs.robot_sim.end_effectors.grippers.piper_gripper.piper_gripper as pg
from my_project.tiaozhanbei.yolo_detect.yolo_utils import init_yolo, init_camera, transform_points_by_homomat, yolo_detect_world_positions
from my_project.tiaozhanbei.empty_cup_place.detect_mini import *

class MultiCameraCupTask:
    def __init__(self):
        self.left_arm = PiperArmController(can_name='can0', has_gripper=True)
        self.right_arm = PiperArmController(can_name='can1', has_gripper=True)
        self.yolo = init_yolo(YOLO_MODEL_CUPS_PATH)
        self.rbt_s = DualPiperNoBody()
        self.gripper = pg.PiperGripper()
        self.visualize = False
        # # æ‘„åƒå¤´å®šä¹‰
        self.cameras = {
            "middle": {"cam": init_camera(camera_id='middle'), "type": "fixed", "c2w": MIDDLE_CAM_C2W},
            #"left": {"cam": init_camera(camera_id='left'), "type": "handeye", "handeye": LEFT_HAND_EYE},
            # "right": {"cam": init_camera(camera_id='right'), "type": "handeye", "handeye": RIGHT_HAND_EYE}
        }
        print(self.cameras)
        print("æ¯å­ä»»åŠ¡åˆå§‹åŒ–å®Œæ¯•")


    def process_gripper_data(self, data, threshold=0.05):
        """
        å¤„ç†å¤¹çˆªæ•°æ®ï¼Œå°†å¤§çš„æ•°æ”¹ä¸º1ï¼Œå°çš„æ•°æ”¹ä¸º0ï¼Œå¹¶è¿”å›å˜åŒ–ç‚¹ç´¢å¼•
        
        å‚æ•°:
            data: è¾“å…¥æ•°ç»„ï¼ŒåŒ…å«å¤¹çˆªå®½åº¦æ•°æ®
            threshold: åˆ¤æ–­å¤§å°çš„é˜ˆå€¼ï¼Œé»˜è®¤0.05
            
        è¿”å›:
            tuple: (å¤„ç†åçš„äºŒè¿›åˆ¶æ•°ç»„, å˜åŒ–ç‚¹ç´¢å¼•åˆ—è¡¨)
        """
        # å°†æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
        arr = np.array(data)
        
        # åˆ›å»ºäºŒè¿›åˆ¶æ•°ç»„ï¼šå¤§äºé˜ˆå€¼è®¾ä¸º1ï¼Œå¦åˆ™è®¾ä¸º0
        binary_arr = (arr > threshold).astype(int)
        
        # æ‰¾åˆ°æ•°å€¼å˜åŒ–çš„ç´¢å¼•
        change_indices = np.where(np.diff(binary_arr) != 0)[0] + 1
        
        return binary_arr.tolist(), change_indices.tolist()
    
    def split_trajectory_by_gripper(self, jv, change_indices, threshold=0.05):
        """
        æ ¹æ®å¤¹çˆªæ•°æ®çš„å˜åŒ–ç‚¹å°†å…³èŠ‚é€Ÿåº¦è½¨è¿¹åˆ†å‰²ä¸ºä¸‰æ®µ
        
        å‚æ•°:
            jv: å…³èŠ‚é€Ÿåº¦æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n,6)çš„äºŒç»´æ•°ç»„
            gripper_data: å¤¹çˆªå®½åº¦æ•°æ®ï¼Œä¸€ç»´æ•°ç»„
            threshold: åˆ¤æ–­å¤¹çˆªå¼€åˆçš„é˜ˆå€¼
            
        è¿”å›:
            dict: åŒ…å«ä¸‰æ®µè½¨è¿¹çš„å­—å…¸ {
                'stage1': ç¬¬ä¸€é˜¶æ®µè½¨è¿¹,
                'stage2': ç¬¬äºŒé˜¶æ®µè½¨è¿¹,
                'stage3': ç¬¬ä¸‰é˜¶æ®µè½¨è¿¹,
                'change_points': å˜åŒ–ç‚¹ç´¢å¼•
            }
        """
        # ç¡®ä¿æœ‰ä¸¤ä¸ªå˜åŒ–ç‚¹
        if len(change_indices) != 2:
            raise ValueError(f"æœŸæœ›2ä¸ªå˜åŒ–ç‚¹,ä½†æ‰¾åˆ°{len(change_indices)}ä¸ª")
        
        # è·å–ä¸¤ä¸ªå˜åŒ–ç‚¹
        cp1, cp2 = change_indices
        
        # åˆ†å‰²è½¨è¿¹
        stage1 = jv[:cp1]      # ç¬¬ä¸€é˜¶æ®µï¼šä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªå˜åŒ–ç‚¹
        stage2 = jv[cp1:cp2]   # ç¬¬äºŒé˜¶æ®µï¼šç¬¬ä¸€ä¸ªå˜åŒ–ç‚¹åˆ°ç¬¬äºŒä¸ªå˜åŒ–ç‚¹
        stage3 = jv[cp2:]      # ç¬¬ä¸‰é˜¶æ®µï¼šç¬¬äºŒä¸ªå˜åŒ–ç‚¹åˆ°ç»“æŸ
        
        return stage1,stage2,stage3
    
    # -------------------------00
    # YOLOå¤šæ‘„åƒå¤´æ£€æµ‹
    # -------------------------
    def detect_cups(self, show=False, eps=0.03):
        """
        ä½¿ç”¨å¤šæ‘„åƒå¤´å’Œ YOLO æ£€æµ‹æ¯å­/æ¯å«å¹¶å»é‡ã€‚
        è¿”å›: [(cls_id, [x, y, z]), ...] ä¸–ç•Œåæ ‡ç³»ä¸‹çš„è´¨å¿ƒåˆ—è¡¨
        """
        all_results = []

        for name, cam_info in self.cameras.items():
            cam = cam_info["cam"]

            try:
                # è·å–å½©è‰²å¸§ç”¨äº YOLO
                depth_frame, color_frame = cam._current_frames()
                color_img = np.asanyarray(color_frame.get_data())

                # YOLO æ£€æµ‹
                detections = self.yolo(color_img, verbose=False)[0]
                if detections is None or len(detections.boxes) == 0:
                    continue

                for (x1, y1, x2, y2), cls_id, conf in zip(
                        detections.boxes.xyxy.cpu().numpy(),
                        detections.boxes.cls.cpu().numpy(),
                        detections.boxes.conf.cpu().numpy()):
                    if conf < 0.3:
                        continue

                    # æ¡†å†…ç‚¹äº‘ï¼ˆæ·±åº¦ç›¸æœºåæ ‡ç³»ï¼‰
                    points_3d = cam.points_in_color_bbox((x1, y1, x2, y2))
                    if len(points_3d) == 0:
                        continue

                    # è½¬ä¸–ç•Œåæ ‡
                    if cam_info["type"] == "fixed":
                        points_world = transform_points_by_homomat(cam_info["c2w"], points_3d)
                    else:
                        points_world = self.rbt_s.transform_point_cloud_handeye(
                            cam_info["handeye"], points_3d,
                            component_name='lft_arm' if name == 'left' else 'rgt_arm'
                        )

                    # è´¨å¿ƒ
                    centroid = points_world.mean(axis=0)
                    all_results.append((int(cls_id), centroid.tolist()))

                # å¯è§†åŒ–å½©è‰²å›¾åƒ
                if show:
                    cv2.imshow(f"{name}_camera", color_img)
                    cv2.waitKey(1)

            except Exception as e:
                print(f"âš ï¸ {name} æ‘„åƒå¤´æ£€æµ‹å¤±è´¥: {e}")
                continue

        if show:
            cv2.destroyAllWindows()

        if not all_results:
            return []

        # ---------------------------
        # æŒ‰ cls_id åˆ†ç»„å¹¶ DBSCAN å»é‡
        # ---------------------------
        deduped_results = []
        all_cls_ids = [r[0] for r in all_results]
        all_positions = np.array([r[1] for r in all_results])
        unique_cls = set(all_cls_ids)

        for cls in unique_cls:
            mask = [i for i, c in enumerate(all_cls_ids) if c == cls]
            cls_positions = all_positions[mask]
            clustering = DBSCAN(eps=eps, min_samples=1).fit(cls_positions)
            labels = clustering.labels_
            for lbl in np.unique(labels):
                cluster_points = cls_positions[labels == lbl]
                centroid = cluster_points.mean(axis=0)
                deduped_results.append((cls, centroid.tolist())) 

        return deduped_results
    
    def crop_pointcloud_world(self, pcd_world, x_range=(0, 0.6), y_range=(0, -0.6), z_range=(0.07, 0.08)):
        """
        åœ¨ä¸–ç•Œåæ ‡ç³»ä¸‹è£å‰ªç‚¹äº‘åˆ°æŒ‡å®šèŒƒå›´
        
        Args:
            pcd_world: ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ç‚¹äº‘æ•°æ® (N, 3)
            x_range: Xè½´èŒƒå›´ (min, max)ï¼Œé»˜è®¤(0, 0.6)
            y_range: Yè½´èŒƒå›´ (min, max)ï¼Œé»˜è®¤(0, -0.6) 
            z_range: Zè½´èŒƒå›´ (min, max)ï¼Œé»˜è®¤(0.07, 0.08)
            
        Returns:
            tuple: (è£å‰ªåçš„ç‚¹äº‘æ•°æ®, åŸå§‹ç‚¹äº‘æ•°é‡, è£å‰ªåç‚¹äº‘æ•°é‡)
        """
        if pcd_world is None or len(pcd_world) == 0:
            print("è¾“å…¥ç‚¹äº‘ä¸ºç©º")
            return None, 0, 0
            
        # è®°å½•åŸå§‹ç‚¹äº‘æ•°é‡
        original_count = len(pcd_world)
        
        # æå–åæ ‡
        x = pcd_world[:, 0]
        y = pcd_world[:, 1] 
        z = pcd_world[:, 2]
        
        # åˆ›å»ºè£å‰ªæ©ç 
        x_mask = (x >= x_range[0]) & (x <= x_range[1])
        y_mask = (y >= y_range[1]) & (y <= y_range[0])  # æ³¨æ„Yè½´èŒƒå›´æ˜¯(0, -0.6)ï¼Œæ‰€ä»¥æ˜¯y >= -0.6 and y <= 0
        z_mask = (z >= z_range[0]) & (z <= z_range[1])
        
        # ç»„åˆæ‰€æœ‰æ©ç 
        combined_mask = x_mask & y_mask & z_mask
        
        # åº”ç”¨æ©ç è£å‰ªç‚¹äº‘
        cropped_pcd = pcd_world[combined_mask]
        cropped_count = len(cropped_pcd)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print(f"ç‚¹äº‘è£å‰ªç»Ÿè®¡:")
        print(f"  åŸå§‹ç‚¹äº‘æ•°é‡: {original_count}")
        print(f"  è£å‰ªåç‚¹äº‘æ•°é‡: {cropped_count}")
        print(f"  è£å‰ªèŒƒå›´: X[{x_range[0]}, {x_range[1]}], Y[{y_range[1]}, {y_range[0]}], Z[{z_range[0]}, {z_range[1]}]")
        print(f"  ä¿ç•™æ¯”ä¾‹: {cropped_count/original_count*100:.2f}%")
        
        if cropped_count > 0:
            # æ‰“å°è£å‰ªåç‚¹äº‘çš„åæ ‡èŒƒå›´
            print(f"  è£å‰ªåç‚¹äº‘èŒƒå›´:")
            print(f"    X: [{cropped_pcd[:, 0].min():.4f}, {cropped_pcd[:, 0].max():.4f}]")
            print(f"    Y: [{cropped_pcd[:, 1].min():.4f}, {cropped_pcd[:, 1].max():.4f}]")
            print(f"    Z: [{cropped_pcd[:, 2].min():.4f}, {cropped_pcd[:, 2].max():.4f}]")
        else:
            print("  è­¦å‘Š: è£å‰ªåæ²¡æœ‰å‰©ä½™ç‚¹äº‘")
            
        return cropped_pcd, original_count, cropped_count
    
    def align_pcd(self, pcd):
        """
        å°†ç‚¹äº‘ä»ç›¸æœºåæ ‡ç³»è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        
        Args:
            pcd: ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹äº‘æ•°æ® (N, 3)
            
        Returns:
            np.ndarray: ä¸–ç•Œåæ ‡ç³»ä¸‹çš„ç‚¹äº‘æ•°æ® (N, 3)
        """
        c2w_mat =  MIDDLE_CAM_C2W # ç›¸æœºåˆ°ä¸–ç•Œçš„å˜æ¢çŸ©é˜µ
        return rm.transform_points_by_homomat(c2w_mat, points=pcd)
    
    def process_pointcloud(self, pcd_camera):

        """
        å®Œæ•´çš„ç‚¹äº‘å¤„ç†æµç¨‹ï¼šç›¸æœºåæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³» -> è£å‰ª
        
        Args:
            pcd_camera: ç›¸æœºåæ ‡ç³»ä¸‹çš„ç‚¹äº‘æ•°æ® (N, 3)
            
        Returns:
            tuple: (è£å‰ªåçš„ç‚¹äº‘æ•°æ®, åŸå§‹ç‚¹äº‘æ•°é‡, è£å‰ªåç‚¹äº‘æ•°é‡)
        """
        # æ­¥éª¤1: è½¬æ¢åˆ°ä¸–ç•Œåæ ‡ç³»
        pcd_world = self.align_pcd(pcd_camera)
        
        # æ­¥éª¤2: è£å‰ªåˆ°æŒ‡å®šèŒƒå›´
        cropped_pcd, original_count, cropped_count = self.crop_pointcloud_world(
            pcd_world, 
            x_range=(0, 0.6), 
            y_range=(0, -0.6), 
            z_range=(0.07, 0.08)
        )
        
        return cropped_pcd, original_count, cropped_count
    
    def print_cropped_pointcloud_with_center(self, cropped_pcd):
        """
        æ‰“å°è£å‰ªåçš„ç‚¹äº‘ï¼ŒæŒ‰é«˜åº¦æ’åºï¼Œå¹¶è®¡ç®—ä¸­å¿ƒç‚¹

        Args:
            cropped_pcd: è£å‰ªåçš„ç‚¹äº‘æ•°æ® (N, 3)
            camera_role: ç›¸æœºè§’è‰²åç§°

        return:
            x,y,z æ¯å£ä¸­å¿ƒç‚¹
        """
        if cropped_pcd is None or len(cropped_pcd) == 0:
            print("æ²¡æœ‰è£å‰ªåçš„ç‚¹äº‘æ•°æ®")
            return
            
        print("\n===  è£å‰ªåç‚¹äº‘è¯¦ç»†ä¿¡æ¯ ===")
        print(f"ç‚¹äº‘æ•°é‡: {len(cropped_pcd)}")

        # æŒ‰é«˜åº¦ï¼ˆZåæ ‡ï¼‰é™åºæ’åºï¼Œä¼˜å…ˆæ˜¾ç¤ºé«˜åº¦é«˜çš„ç‚¹
        sorted_indices = np.argsort(cropped_pcd[:, 2])[::-1]  # é™åºæ’åº
        sorted_pcd = cropped_pcd[sorted_indices]

        # æ‰“å°å‰20ä¸ªæœ€é«˜ç‚¹ï¼ˆé¿å…è¾“å‡ºè¿‡å¤šï¼‰
        print(f"\nå‰20ä¸ªæœ€é«˜ç‚¹ï¼ˆæŒ‰é«˜åº¦é™åºï¼‰:")
        print("åºå·    Xåæ ‡(m)    Yåæ ‡(m)    Zåæ ‡(m)    é«˜åº¦(cm)")
        print("-" * 60)
        for i in range(min(20, len(sorted_pcd))):
            point = sorted_pcd[i]
            print(f"{i+1:3d}    {point[0]:8.4f}    {point[1]:8.4f}    {point[2]:8.4f}    {point[2]*100:6.2f}")

        if len(sorted_pcd) > 20:
            print(f"... (è¿˜æœ‰ {len(sorted_pcd) - 20} ä¸ªç‚¹æœªæ˜¾ç¤º)")

        # è®¡ç®—ä¸­å¿ƒç‚¹
        center_point = np.mean(cropped_pcd, axis=0)
        print(f"\nç‚¹äº‘ä¸­å¿ƒç‚¹:")
        print(f"  X: {center_point[0]:.4f} m")
        print(f"  Y: {center_point[1]:.4f} m") 
        print(f"  Z: {center_point[2]:.4f} m ({center_point[2]*100:.2f} cm)")

        # è®¡ç®—ç‚¹äº‘èŒƒå›´
        min_coords = np.min(cropped_pcd, axis=0)
        max_coords = np.max(cropped_pcd, axis=0)
        print(f"\nç‚¹äº‘èŒƒå›´:")
        print(f"  X: [{min_coords[0]:.4f}, {max_coords[0]:.4f}] m (è·¨åº¦: {max_coords[0]-min_coords[0]:.4f} m)")
        print(f"  Y: [{min_coords[1]:.4f}, {max_coords[1]:.4f}] m (è·¨åº¦: {max_coords[1]-min_coords[1]:.4f} m)")
        print(f"  Z: [{min_coords[2]:.4f}, {max_coords[2]:.4f}] m (è·¨åº¦: {max_coords[2]-min_coords[2]:.4f} m)")

        # è®¡ç®—é«˜åº¦ç»Ÿè®¡
        heights = cropped_pcd[:, 2]
        print(f"\né«˜åº¦ç»Ÿè®¡:")
        print(f"  å¹³å‡é«˜åº¦: {np.mean(heights):.4f} m ({np.mean(heights)*100:.2f} cm)")
        print(f"  æœ€é«˜ç‚¹: {np.max(heights):.4f} m ({np.max(heights)*100:.2f} cm)")
        print(f"  æœ€ä½ç‚¹: {np.min(heights):.4f} m ({np.min(heights)*100:.2f} cm)")
        print(f"  é«˜åº¦æ ‡å‡†å·®: {np.std(heights):.4f} m ({np.std(heights)*100:.2f} cm)")

        print("=" * 50)

        return center_point[0],center_point[1],center_point[2]
    
    def detect_cup_use_cloud_points(self):
        for name, cam_info in self.cameras.items():
            cam = cam_info["cam"]

            while True:
                # è·å–ç›¸æœºæ•°æ®
                pcd, pcd_color, depth_img, color_img = cam.get_pcd_texture_depth()
                
                if pcd is not None:
                    # å¤„ç†ç‚¹äº‘ï¼šç›¸æœºåæ ‡ç³» -> ä¸–ç•Œåæ ‡ç³» -> è£å‰ª
                    cropped_pcd, original_count, cropped_count = self.process_pointcloud(pcd)
                    
                    # if cropped_pcd is not None and len(cropped_pcd) > 0:
                    #     #print(f"[{role}ç›¸æœº] å¤„ç†å®Œæˆ: {len(cropped_pcd)} ä¸ªç‚¹")
                    # else:
                    #     #print(f"[{role}ç›¸æœº] æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç‚¹äº‘")

                    # æ‰“å°è£å‰ªåçš„ç‚¹äº‘ï¼ˆæŒ‰é«˜åº¦æ’åºï¼‰å¹¶è®¡ç®—ä¸­å¿ƒç‚¹
                    if cropped_pcd is not None and len(cropped_pcd) > 0:
                        cup_x,cup_y,cup_z = self.print_cropped_pointcloud_with_center(cropped_pcd)
                        
                        return cup_x,cup_y,cup_z
                                        
                    else:
                        print("è·å–ç‚¹äº‘å¤±è´¥")

    def process_gripper_data(self, data, threshold=0.05):
        """
        å¤„ç†å¤¹çˆªæ•°æ®ï¼Œå°†å¤§çš„æ•°æ”¹ä¸º1ï¼Œå°çš„æ•°æ”¹ä¸º0ï¼Œå¹¶è¿”å›å˜åŒ–ç‚¹ç´¢å¼•
        
        å‚æ•°:
            data: è¾“å…¥æ•°ç»„ï¼ŒåŒ…å«å¤¹çˆªå®½åº¦æ•°æ®
            threshold: åˆ¤æ–­å¤§å°çš„é˜ˆå€¼ï¼Œé»˜è®¤0.05
            
        è¿”å›:
            tuple: (å¤„ç†åçš„äºŒè¿›åˆ¶æ•°ç»„, å˜åŒ–ç‚¹ç´¢å¼•åˆ—è¡¨)
        """
        # å°†æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
        arr = np.array(data)
        
        # åˆ›å»ºäºŒè¿›åˆ¶æ•°ç»„ï¼šå¤§äºé˜ˆå€¼è®¾ä¸º1ï¼Œå¦åˆ™è®¾ä¸º0
        binary_arr = (arr > threshold).astype(int)
        
        # æ‰¾åˆ°æ•°å€¼å˜åŒ–çš„ç´¢å¼•
        change_indices = np.where(np.diff(binary_arr) != 0)[0] + 1
        
        return binary_arr.tolist(), change_indices.tolist()
    
    def split_trajectory_by_gripper(self, jv, change_indices, threshold=0.05):
        """
        æ ¹æ®å¤¹çˆªæ•°æ®çš„å˜åŒ–ç‚¹å°†å…³èŠ‚é€Ÿåº¦è½¨è¿¹åˆ†å‰²ä¸ºä¸‰æ®µ
        
        å‚æ•°:
            jv: å…³èŠ‚é€Ÿåº¦æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n,6)çš„äºŒç»´æ•°ç»„
            gripper_data: å¤¹çˆªå®½åº¦æ•°æ®ï¼Œä¸€ç»´æ•°ç»„
            threshold: åˆ¤æ–­å¤¹çˆªå¼€åˆçš„é˜ˆå€¼
            
        è¿”å›:
            dict: åŒ…å«ä¸‰æ®µè½¨è¿¹çš„å­—å…¸ {
                'stage1': ç¬¬ä¸€é˜¶æ®µè½¨è¿¹,
                'stage2': ç¬¬äºŒé˜¶æ®µè½¨è¿¹,
                'stage3': ç¬¬ä¸‰é˜¶æ®µè½¨è¿¹,
                'change_points': å˜åŒ–ç‚¹ç´¢å¼•
            }
        """
        # ç¡®ä¿æœ‰ä¸¤ä¸ªå˜åŒ–ç‚¹
        if len(change_indices) != 2:
            raise ValueError(f"æœŸæœ›2ä¸ªå˜åŒ–ç‚¹,ä½†æ‰¾åˆ°{len(change_indices)}ä¸ª")
        
        # è·å–ä¸¤ä¸ªå˜åŒ–ç‚¹
        cp1, cp2 = change_indices
        
        # åˆ†å‰²è½¨è¿¹
        stage1 = jv[:cp1]      # ç¬¬ä¸€é˜¶æ®µï¼šä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªå˜åŒ–ç‚¹
        stage2 = jv[cp1:cp2]   # ç¬¬äºŒé˜¶æ®µï¼šç¬¬ä¸€ä¸ªå˜åŒ–ç‚¹åˆ°ç¬¬äºŒä¸ªå˜åŒ–ç‚¹
        stage3 = jv[cp2:]      # ç¬¬ä¸‰é˜¶æ®µï¼šç¬¬äºŒä¸ªå˜åŒ–ç‚¹åˆ°ç»“æŸ
        
        return stage1,stage2,stage3

    # -------------------------
    # ç”ŸæˆæŠ“å–å§¿æ€
    # -------------------------
    def create_grasps(self):
        if os.path.exists(GRASP_PATH_CUPS):
            return
        print("â˜• ç”ŸæˆæŠ“å–å§¿æ€ä¸­...")
        obj = mcm.CollisionModel(CUP_MODEL_PATH)
        grasps = gpa.plan_gripper_grasps(
            self.gripper, obj,
            angle_between_contact_normals=rm.radians(175),
            rotation_interval=rm.radians(15),
            max_samples=10,
            min_dist_between_sampled_contact_points=0.01,
            contact_offset=0.01
        )
        
        grasps.save_to_disk(GRASP_PATH_CUPS)
        print(f"âœ… ä¿å­˜æŠ“å–å§¿æ€ï¼Œå…± {len(grasps)} ä¸ª")

    # -------------------------
    # æ‰§è¡Œ pick & place
    # -------------------------
    def execute_pick_place(self, pick_pos, place_pos, arm:PiperArmController, robot, obstacles):
        block = mcm.CollisionModel(CUP_MODEL_PATH)
        block.pos = np.array(pick_pos, dtype=float)
        goal_rot = rm.rotmat_from_euler(0, 0, 0)
        planner = ppp.PickPlacePlanner(robot)
        grasps = gg.GraspCollection.load_from_disk(GRASP_PATH_CUPS)
        print(len(grasps))
        mot_data = planner.gen_pick_and_place(
            obj_cmodel=block,
            end_jnt_values=robot.get_jnt_values(),
            grasp_collection=grasps,
            goal_pose_list=[(place_pos, goal_rot)],
            pick_approach_direction= -rm.const.z_ax,
            place_approach_distance_list=[.05],
            place_depart_distance_list=[.07],
            pick_approach_distance=.03,
            pick_depart_distance=.05,
            obstacle_list=obstacles,
            use_rrt=False
        )
        if mot_data is None:
            print("âš ï¸ è½¨è¿¹è§„åˆ’å¤±è´¥ï¼")
            return None

        # å…ˆæ‰§è¡Œæœºæ¢°è‡‚åŠ¨ä½œ
        # for jv, ev in zip(mot_data.jv_list, mot_data.ev_list):
        #     arm.move_jntspace_path(jv, )
        #     arm.gripper_control(angle=0.04 if ev >= 0.09 else 0.0, effort=0)
        #     time.sleep(0.2)

        jv = mot_data.jv_list
        ev = mot_data.ev_list

        binary_arr, change_indices = self.process_gripper_data(ev)
        print(change_indices)
        approach_path,pick_path,depart_path = self.split_trajectory_by_gripper(jv,change_indices)
        arm.open_gripper(width=0.03)
        arm.move_j(jv[0],speed=20,block=True)

        time.sleep(0.1)
        arm.move_jntspace_path(approach_path,speed=20)
        time.sleep(0.1)
        arm.close_gripper()
        time.sleep(0.1)
        arm.move_jntspace_path(pick_path,speed=20)
        time.sleep(0.1)
        arm.open_gripper(width = 0.03)
        time.sleep(0.1) 
        arm.move_jntspace_path(depart_path,speed=20)

        # arm.move_j(mot_data.jv_list[0],speed=10)
        # arm.move_jntspace_path(mot_data.jv_list)

        return mot_data

    # -------------------------
    # æœºæ¢°è‡‚é€‰æ‹©
    # -------------------------
    def choose_arm(self, pos):
        _, y = pos
        if y[1] > -0.3:
            return self.left_arm, self.rbt_s.use_lft()
        else:
            return self.right_arm, self.rbt_s.use_rgt()

    
    # -------------------------
    # ä¸»ä»»åŠ¡å…¥å£
    # -------------------------
    def run(self, show_camera=False):
        if self.visualize:
            base = wd.World(cam_pos=[.5, .5, .5], lookat_pos=[0, 0, 0])
            mgm.gen_frame().attach_to(base)

        # éšœç¢ç‰©
        obstacles = [
            mcm.gen_box(xyz_lengths=[0.8, 1.4, 1], pos=np.array([0.34, -0.2985, -0.5])),
            mcm.gen_box(xyz_lengths=[0.03, 0.03, 0.555], pos=np.array([-0.05, -0.2985, 0.2775])),
            mcm.gen_box(xyz_lengths=[0.08, 0.16, 0.14], pos=np.array([-0.03, -0.23, 0.07])),
            mcm.gen_box(xyz_lengths=[0.08, 0.16, 0.14], pos=np.array([-0.03, -0.375, 0.07]))
        ]
        if self.visualize:
            [o.attach_to(base) for o in obstacles]

        if self.visualize:
            self.create_grasps()
        else:
            self.create_grasps()

        self.left_arm.move_j([0] * 6, speed=20)
        self.right_arm.move_j([0] * 6, speed=20)
        time_start = time.time()
        objects = self.detect_cups(show=show_camera)
        if not objects:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°æ¯å­æˆ–æ¯å«ï¼")
            return False
        
        #è¿”å›æ¯å­åæ ‡
        cup_x,cup_y,cup_z = self.detect_cup_use_cloud_points()
        # æ‰¾åˆ°æ¯å­å’Œç›®æ ‡ä½ç½®
        #pick_obj = next((pos for cls_id, pos in objects if cls_id == 1), None)
        pick_obj = [cup_x,cup_y,cup_z]
        print(f"pick_obj:{pick_obj}")
        place_obj = next((pos for cls_id, pos in objects if cls_id == 0), None)
        if pick_obj is None or place_obj is None:
            print("âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ°æ¯å­æˆ–æ¯å«ï¼")
            return False
        # å°† pick_obj çš„ z åæ ‡æ”¹ä¸º 0
        pick_obj_mod = pick_obj.copy()
        pick_obj_mod[2] = 0.0

        # æ‰§è¡ŒæŠ“æ”¾ï¼Œå­˜å‚¨è½¨è¿¹ç”¨äºç»Ÿä¸€ä»¿çœŸ
        arm, robot = self.choose_arm((1, pick_obj))
        print(f"\nâ˜• æŠ“å–æ¯å­ {pick_obj} â†’ æ”¾ç½® {place_obj}")
        mot_data = self.execute_pick_place(pick_obj_mod, place_obj, arm, robot, obstacles)
        if mot_data is None:
            print("âŒ æŠ“å–å¤±è´¥")
            return False
        end_time = time.time()

        print(f"'æ¨ç†ç”¨æ—¶{end_time-time_start}'")
        # -------------------------
        # ç»Ÿä¸€ä»¿çœŸå›æ”¾
        # -------------------------
        if self.visualize:
            print("\nğŸ¬ å¼€å§‹ç»Ÿä¸€ä»¿çœŸå›æ”¾...")
            for mesh in mot_data.mesh_list:
                mesh.attach_to(base)
                mesh.show_cdprim()
            base.run()

        print("âœ… æŠ“æ”¾æ¯å­å®Œæˆï¼")
        return True


# ==================================
# main
# ==================================
def main():
    task = MultiCameraCupTask()
    try:
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)
        success = task.run(show_camera=False)
        print("ä»»åŠ¡æˆåŠŸ âœ…" if success else "ä»»åŠ¡å¤±è´¥ âŒ")
    except KeyboardInterrupt:
        print("\nâš ï¸ æ•è·åˆ° Ctrl+Cï¼Œæœºæ¢°è‡‚å›åˆ°å…¨é›¶ä½...")
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)
    except Exception as e:
        import traceback
        traceback.print_exc()
        print("âš ï¸ å‡ºç°å¼‚å¸¸ï¼Œæœºæ¢°è‡‚å›åˆ°å…¨é›¶ä½...")
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)


if __name__ == '__main__':
    main()
