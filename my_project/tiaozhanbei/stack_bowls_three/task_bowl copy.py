#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time : 2025/10/25 11:11
# @Author : ZhangXi
#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time : 2025/10/25
# @Author : ZhangXi

import os
import time
import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import wrs.basis.robot_math as rm
from my_project.tiaozhanbei.stack_bowls_three.constant import YOLO_MODEL_BOWLS_PATH, BOWL_MODEL_PATH, GRASP_PATH_BOWLS, \
    TARGET_POSITIONS, MIDDLE_CAM_C2W, LEFT_HAND_EYE, RIGHT_HAND_EYE
from wrs import wd, rm, mgm, mcm, ppp, gg, gpa
from wrs.robot_sim.robots.piper.piper_dual_arm import DualPiperNoBody
from wrs.robot_con.piper.piper import PiperArmController
import wrs.robot_sim.end_effectors.grippers.piper_gripper.piper_gripper as pg
from my_project.tiaozhanbei.yolo_detect.yolo_utils import init_yolo, init_camera, transform_points_by_homomat, yolo_detect_world_positions


class MultiCameraBowlTask:
    def __init__(self, resources=None):
        if resources:
            print("ğŸ¥£ ä½¿ç”¨å¤–éƒ¨ ResourceManager èµ„æº")
            self.left_arm = resources.left_arm
            self.right_arm = resources.right_arm
            self.cameras = resources.cameras
            self.yolo = resources.yolo_bowl
        else:
            print("ğŸ¥£ ç‹¬ç«‹åˆå§‹åŒ– Bowl ä»»åŠ¡èµ„æº")
            self.left_arm = PiperArmController(can_name='can0', has_gripper=True)
            self.right_arm = PiperArmController(can_name='can1', has_gripper=True)
            self.yolo = init_yolo(YOLO_MODEL_BOWLS_PATH)
            self.cameras = {
                "middle": {"cam": init_camera(camera_id='middle'), "type": "fixed", "c2w": MIDDLE_CAM_C2W},
            }
        # ========== ç¡¬ä»¶ä¸æ¨¡å‹ ==========

        self.rbt_s = DualPiperNoBody()
        self.gripper = pg.PiperGripper()
 

    def detect_bowls(self, show=False, eps=0.03):
        """
        ä½¿ç”¨ YOLO + ç‚¹äº‘æ£€æµ‹ç¢—ï¼Œè¿”å›ä¸–ç•Œåæ ‡ç³»ä¸‹çš„è´¨å¿ƒï¼ŒæŒ‰ Y å€¼æ’åºé å·¦å…ˆæŠ“
        """
        all_results = []

        for name, cam_info in self.cameras.items():
            cam = cam_info["cam"]

            try:
                # è·å–å½©è‰²å¸§ç”¨äº YOLO
                depth_frame, color_frame = cam._current_frames()
                color_img = np.asanyarray(color_frame.get_data())

                # YOLO æ£€æµ‹
                detections = self.yolo(color_img, verbose=False)[0]
                if detections is None or len(detections.boxes) == 0:
                    continue

                for (x1, y1, x2, y2), cls_id, conf in zip(
                        detections.boxes.xyxy.cpu().numpy(),
                        detections.boxes.cls.cpu().numpy(),
                        detections.boxes.conf.cpu().numpy()):
                    if conf < 0.3:
                        continue

                    # æ¡†å†…ç‚¹äº‘ï¼ˆæ·±åº¦ç›¸æœºåæ ‡ç³»ï¼‰
                    points_3d = cam.points_in_color_bbox((x1, y1, x2, y2))
                    if len(points_3d) == 0:
                        continue

                    # è½¬ä¸–ç•Œåæ ‡
                    if cam_info["type"] == "fixed":
                        points_world = transform_points_by_homomat(cam_info["c2w"], points_3d)
                    else:
                        points_world = self.rbt_s.transform_point_cloud_handeye(
                            cam_info["handeye"], points_3d,
                            component_name='lft_arm' if name == 'left' else 'rgt_arm'
                        )

                    # è´¨å¿ƒ
                    centroid = points_world.mean(axis=0)
                    all_results.append((int(cls_id), centroid.tolist()))

                # å¯è§†åŒ–å½©è‰²å›¾åƒ
                if show:
                    cv2.imshow(f"{name}_camera", color_img)
                    cv2.waitKey(1)

            except Exception as e:
                print(f"âš ï¸ {name} æ‘„åƒå¤´æ£€æµ‹å¤±è´¥: {e}")
                continue

        if show:
            cv2.destroyAllWindows()

        if not all_results:
            return []

        # ---------------------------
        # å»é‡èšç±»
        # ---------------------------
        points_array = np.array([pos for _, pos in all_results])
        clustering = DBSCAN(eps=eps, min_samples=1).fit(points_array)
        deduped_results = []
        for lbl in np.unique(clustering.labels_):
            cluster_pts = points_array[clustering.labels_ == lbl]
            centroid = cluster_pts.mean(axis=0)
            deduped_results.append((1, centroid.tolist()))  # cls_idç»Ÿä¸€ä¸º1

        # æŒ‰ Y å€¼æ’åºï¼ˆé å·¦å…ˆæŠ“ï¼‰
        deduped_results.sort(key=lambda x: -x[1][1])

        return deduped_results

    # -------------------------
    # ç”ŸæˆæŠ“å–å§¿æ€
    # -------------------------
    def create_grasps(self, base):
        if os.path.exists(GRASP_PATH_BOWLS):
            return
        print("ğŸ¥£ ç”ŸæˆæŠ“å–å§¿æ€ä¸­...")
        obj = mcm.CollisionModel(BOWL_MODEL_PATH)
        obj.attach_to(base)
        grasps = gpa.plan_gripper_grasps(
            self.gripper, obj,
            angle_between_contact_normals=rm.radians(175),
            rotation_interval=rm.radians(15),
            max_samples=20,
            min_dist_between_sampled_contact_points=0.03,
            contact_offset=0.01
        )
        grasps.save_to_disk(GRASP_PATH_BOWLS)
        print(f"âœ… ä¿å­˜æŠ“å–å§¿æ€ï¼Œå…± {len(grasps)} ä¸ª")

    def _execute_trajectory(self, arm, mot_data, base, show_sim=False):
        for jv, ev in zip(mot_data.jv_list, mot_data.ev_list):
            arm.move_j(jv, speed=10)
            arm.gripper_control(angle=0.05 if ev >= 0.09 else 0.0, effort=0)
            time.sleep(0.2)

        if not show_sim:
            return

        # -------------------------
        # è®¾ç½®ä»¿çœŸåŠ¨ç”»
        # -------------------------
        class AnimeData:
            def __init__(self, mot_data):
                self.mot_data = mot_data
                self.counter = 0

        anime_data = AnimeData(mot_data)

        def update(task, anime_data=anime_data):
            if anime_data.counter > 0:
                anime_data.mot_data.mesh_list[anime_data.counter - 1].detach()
            if anime_data.counter >= len(anime_data.mot_data):
                return task.done  # å½“å‰ç‰©ä½“åŠ¨ç”»æ’­æ”¾å®Œæˆ
            mesh_model = anime_data.mot_data.mesh_list[anime_data.counter]
            mesh_model.attach_to(base)
            mesh_model.show_cdprim()
            # æŒ‰ç©ºæ ¼æ’­æ”¾ä¸‹ä¸€å¸§
            if base.inputmgr.keymap.get('space', False):
                anime_data.counter += 1
            return task.cont

        base.taskMgr.add(update, "update")

        # -------------------------
        # éé˜»å¡å¾ªç¯ç­‰å¾…çª—å£å…³é—­
        # -------------------------
        try:
            while not base.app_closed:  # base.app_closed è¡¨ç¤ºçª—å£æ˜¯å¦å…³é—­
                base.taskMgr.step()
                time.sleep(0.01)
        except Exception:
            pass

    # -------------------------
    # æ‰§è¡Œ pick & place
    # -------------------------
    def execute_pick_place(self, start_pos, goal_pos, arm, robot, obstacles):
        cls_id, pos = start_pos
        block = mcm.CollisionModel(BOWL_MODEL_PATH)
        block.pos = np.array(pos, dtype=float)
        goal_rot = rm.rotmat_from_euler(0, 0, 0)
        planner = ppp.PickPlacePlanner(robot)
        grasps = gg.GraspCollection.load_from_disk(GRASP_PATH_BOWLS)

        mot_data = planner.gen_pick_and_place(
            obj_cmodel=block,
            end_jnt_values=robot.get_jnt_values(),
            grasp_collection=grasps,
            goal_pose_list=[(goal_pos, goal_rot)],
            pick_approach_direction=-rm.const.z_ax,
            place_approach_distance_list=[.05],
            place_depart_distance_list=[.05],
            pick_approach_distance=.05,
            pick_depart_distance=.05,
            obstacle_list=obstacles,
            use_rrt=True
        )
        if mot_data is None:
            print("âš ï¸ è½¨è¿¹è§„åˆ’å¤±è´¥ï¼")
            return None

        # å…ˆæ‰§è¡Œæœºæ¢°è‡‚åŠ¨ä½œ
        self._execute_trajectory(arm, mot_data)
        return mot_data

    # -------------------------
    # æœºæ¢°è‡‚é€‰æ‹©
    # -------------------------
    def choose_arm(self, block):
        # block = (cls_id, [x, y, z])
        pos = block[1]
        if pos[1] > -0.3:
            return self.left_arm, self.rbt_s.use_lft()
        else:
            return self.right_arm, self.rbt_s.use_rgt()

    # -------------------------
    # ä¸»ä»»åŠ¡å…¥å£
    # -------------------------
    def run(self, show_camera=False):
        base = wd.World(cam_pos=[.5, .5, .5], lookat_pos=[0, 0, 0])
        mgm.gen_frame().attach_to(base)
        obstacles = [
            mcm.gen_box(xyz_lengths=[0.8, 1.4, 1], pos=np.array([0.34, -0.2985, -0.5])),
            mcm.gen_box(xyz_lengths=[0.03, 0.03, 0.555], pos=np.array([-0.05, -0.2985, 0.2775])),
            mcm.gen_box(xyz_lengths=[0.08, 0.16, 0.14], pos=np.array([-0.03, -0.23, 0.07])),
            mcm.gen_box(xyz_lengths=[0.08, 0.16, 0.14], pos=np.array([-0.03, -0.375, 0.07]))
        ]
        [o.attach_to(base) for o in obstacles]

        self.create_grasps(base)
        self.left_arm.move_j([0] * 6, speed=20)
        self.right_arm.move_j([0] * 6, speed=20)

        # æ£€æµ‹ç¢—
        blocks = self.detect_bowls(show=show_camera)
        if len(blocks) < 3:
            print(f"âš ï¸ æ£€æµ‹åˆ° {len(blocks)} ä¸ªç¢—ï¼Œä¸è¶³ä¸‰ä¸ªï¼")
            return False

        print("ğŸ”¹ æ£€æµ‹åˆ°çš„ç¢—åæ ‡ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰ï¼š")
        for i, block in enumerate(blocks):
            cls_id, pos = block
            print(f"ç¢— {i + 1}: {pos}")

        # æŒ‰é¡ºåºæŠ“å–å¹¶æ”¾ç½®åˆ° TARGET_POSITIONS
        all_mot_data = []
        for block, goal_pos in zip(blocks, TARGET_POSITIONS):
            arm, robot = self.choose_arm(block)
            mot_data = self.execute_pick_place(block, np.array(goal_pos), arm, robot, obstacles)
            if mot_data is not None:
                all_mot_data.append((mot_data, base))
            else:
                print(f"âš ï¸ ç¢— {block} çš„æŠ“å–æ”¾ç½®å¤±è´¥ï¼")

        # ç»Ÿä¸€ä»¿çœŸå›æ”¾
        if all_mot_data:
            print("\nğŸ¬ å¼€å§‹ç»Ÿä¸€ä»¿çœŸå›æ”¾...")
            for mot_data, base in all_mot_data:
                for mesh in mot_data.mesh_list:
                    mesh.attach_to(base)
                    mesh.show_cdprim()
            base.run()  # è‡ªåŠ¨æ’­æ”¾

        return True


# ==================================
# main
# ==================================
def main():
    task = MultiCameraBowlTask()
    try:
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)
        success = task.run(show_camera=False)
        print("ä»»åŠ¡æˆåŠŸ âœ…" if success else "ä»»åŠ¡å¤±è´¥ âŒ")
    except KeyboardInterrupt:
        print("\nâš ï¸ æ•è·åˆ° Ctrl+Cï¼Œæœºæ¢°è‡‚å›åˆ°å…¨é›¶ä½...")
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)
    except Exception as e:
        import traceback
        traceback.print_exc()
        print("âš ï¸ å‡ºç°å¼‚å¸¸ï¼Œæœºæ¢°è‡‚å›åˆ°å…¨é›¶ä½...")
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)


if __name__ == '__main__':
    main()
