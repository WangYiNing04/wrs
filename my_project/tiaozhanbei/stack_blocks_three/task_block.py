#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time : 2025/10/18 9:34
# @Author : ZhangXi

import os
import time
import cv2
import numpy as np
from sklearn.cluster import DBSCAN
import wrs.basis.robot_math as rm
from my_project.tiaozhanbei.stack_blocks_three.constant import YOLO_MODEL_BLOCKS_PATH, BLOCK_MODEL_PATH, GRASP_PATH_BLOCKS, \
    TARGET_POSITIONS, MIDDLE_CAM_C2W, LEFT_HAND_EYE, RIGHT_HAND_EYE
from wrs import wd, rm, mgm, mcm, ppp, gg, gpa
from wrs.robot_sim.robots.piper.piper_dual_arm import DualPiperNoBody
from wrs.robot_con.piper.piper import PiperArmController
import wrs.robot_sim.end_effectors.grippers.piper_gripper.piper_gripper as pg
from my_project.tiaozhanbei.yolo_detect.yolo_utils import init_yolo, init_camera, transform_points_by_homomat, yolo_detect_world_positions

class MultiCameraBlockTask:
    def __init__(self):
        # ========== ç¡¬ä»¶ä¸æ¨¡å‹ ==========
        self.left_arm = PiperArmController(can_name='can0', has_gripper=True)
        self.right_arm = PiperArmController(can_name='can1', has_gripper=True)
        self.rbt_s = DualPiperNoBody()
        self.gripper = pg.PiperGripper()
        self.yolo = init_yolo(YOLO_MODEL_BLOCKS_PATH)

        # æ‘„åƒå¤´å®šä¹‰
        self.cameras = {
            "middle": {"cam": init_camera(camera_id='middle'), "type": "fixed", "c2w": MIDDLE_CAM_C2W},
            #"left": {"cam": init_camera(camera_id='left'), "type": "handeye", "handeye": LEFT_HAND_EYE},
            #"right": {"cam": init_camera(camera_id='right'), "type": "handeye", "handeye": RIGHT_HAND_EYE}
        }


    # -------------------------
    # ç‚¹äº‘è£åˆ‡ + é¢œè‰²èšç±»æ£€æµ‹
    # -------------------------
    def detect_blocks(self, show=False, eps=0.03):
        """
        ä½¿ç”¨ YOLO + æ·±åº¦ç‚¹äº‘æ£€æµ‹æ–¹å—ï¼Œè¿”å›ä¸–ç•Œåæ ‡ç³»ä¸‹çš„è´¨å¿ƒï¼ŒæŒ‰é¢œè‰²è¿”å›
        """
        all_results = []

        for name, cam_info in self.cameras.items():
            cam = cam_info["cam"]
            try:
                # è·å–å½©è‰²å¸§ç”¨äº YOLO
                depth_frame, color_frame = cam._current_frames()
                color_img = np.asanyarray(color_frame.get_data())
                depth_img = np.asanyarray(depth_frame.get_data())

                # YOLO æ£€æµ‹
                detections = self.yolo(color_img, verbose=False)[0]
                if detections is None or len(detections.boxes) == 0:
                    continue

                for (x1, y1, x2, y2), cls_id, conf in zip(
                        detections.boxes.xyxy.cpu().numpy(),
                        detections.boxes.cls.cpu().numpy(),
                        detections.boxes.conf.cpu().numpy()):
                    if conf < 0.1:
                        continue

                    # æ¡†å†…ç‚¹äº‘ï¼ˆæ·±åº¦ç›¸æœºåæ ‡ç³»ï¼‰
                    points_3d = cam.points_in_color_bbox((x1, y1, x2, y2))

                    # å¦‚æœç‚¹äº‘ä¸ºç©ºï¼Œç”¨æ¡†ä¸­å¿ƒåƒç´ æ·±åº¦ä»£æ›¿
                    if len(points_3d) == 0:
                        cx, cy = int((x1 + x2) / 2), int((y1 + y2) / 2)
                        z = depth_img[cy, cx]
                        if z == 0:
                            continue  # depth æ— æ•ˆå°±è·³è¿‡
                        # å°†åƒç´ åæ ‡è½¬æ¢åˆ°ç›¸æœºåæ ‡ç³»
                        fx, fy, cx_cam, cy_cam = cam.get_intrinsics()  # ä½ éœ€è¦ä¿è¯ç›¸æœºæœ‰è¿™ä¸ªæ–¹æ³•
                        x_cam = (cx - cx_cam) * z / fx
                        y_cam = (cy - cy_cam) * z / fy
                        points_3d = np.array([[x_cam, y_cam, z]])

                    # è½¬ä¸–ç•Œåæ ‡
                    if cam_info["type"] == "fixed":
                        points_world = transform_points_by_homomat(cam_info["c2w"], points_3d)
                    else:
                        points_world = self.rbt_s.transform_point_cloud_handeye(
                            cam_info["handeye"], points_3d,
                            component_name='lft_arm' if name == 'left' else 'rgt_arm'
                        )

                            # ---------------------------
                    # ç­›é€‰æœ‰æ•ˆç‚¹ï¼ˆç§»é™¤æ— æ•ˆåŒºåŸŸï¼‰
                    # ---------------------------
                    valid_mask = (
                        (points_world[:, 0] <= 0.6) &   # X â‰¤ 0.6
                        (points_world[:, 2] >= 0) &      # Z â‰¥ 0
                        (points_world[:, 1] <= 0.1) &    # Y â‰¤ 0.1
                        (points_world[:, 1] >= -0.7)     # Y â‰¥ -0.7
                    )
                    points_world = points_world[valid_mask]
                    
                    # è´¨å¿ƒ
                    centroid = points_world.mean(axis=0)
                    all_results.append((int(cls_id), centroid.tolist()))

                # å¯è§†åŒ–å½©è‰²å›¾åƒ
                if show:
                    cv2.imshow(f"{name}_camera", color_img)
                    cv2.waitKey(1)

            except Exception as e:
                print(f"âš ï¸ {name} æ‘„åƒå¤´æ£€æµ‹å¤±è´¥: {e}")
                continue

        if show:
            cv2.destroyAllWindows()

        if not all_results:
            return []

        # æŒ‰é¢œè‰² id æ’åºï¼ˆçº¢0 â†’ ç»¿1 â†’ è“2ï¼‰
        COLOR_SEQUENCE = [0, 1, 2] # <--- ä¿®æ”¹ï¼šå°† 1,2,3 æ”¹ä¸º 0,1,2
        color_to_block = {}
        for color_id in COLOR_SEQUENCE:
            for cls, pos in all_results:
                if cls == color_id:
                    color_to_block[color_id] = (cls, pos)
                    break

        # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°ä¸‰ç§é¢œè‰²
        if len(color_to_block) < 3:
            print(f"âš ï¸ æ£€æµ‹åˆ°çš„é¢œè‰²ä¸è¶³ä¸‰ä¸ªï¼Œä»…æ£€æµ‹åˆ°: {list(color_to_block.keys())}")
            return []

        return [color_to_block[cid] for cid in COLOR_SEQUENCE]


    def process_gripper_data(self, data, threshold=0.1):
        """
        å¤„ç†å¤¹çˆªæ•°æ®ï¼Œå°†å¤§çš„æ•°æ”¹ä¸º1ï¼Œå°çš„æ•°æ”¹ä¸º0ï¼Œå¹¶è¿”å›å˜åŒ–ç‚¹ç´¢å¼•
        
        å‚æ•°:
            data: è¾“å…¥æ•°ç»„ï¼ŒåŒ…å«å¤¹çˆªå®½åº¦æ•°æ®
            threshold: åˆ¤æ–­å¤§å°çš„é˜ˆå€¼ï¼Œé»˜è®¤0.05
            
        è¿”å›:
            tuple: (å¤„ç†åçš„äºŒè¿›åˆ¶æ•°ç»„, å˜åŒ–ç‚¹ç´¢å¼•åˆ—è¡¨)
        """
        # å°†æ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
        arr = np.array(data)
        
        # åˆ›å»ºäºŒè¿›åˆ¶æ•°ç»„ï¼šå¤§äºé˜ˆå€¼è®¾ä¸º1ï¼Œå¦åˆ™è®¾ä¸º0
        binary_arr = (arr > threshold).astype(int)
        
        # æ‰¾åˆ°æ•°å€¼å˜åŒ–çš„ç´¢å¼•
        change_indices = np.where(np.diff(binary_arr) != 0)[0] + 1
        
        return binary_arr.tolist(), change_indices.tolist()
    

    def split_trajectory_by_gripper(self, jv, change_indices, threshold=0.05):
        """
        æ ¹æ®å¤¹çˆªæ•°æ®çš„å˜åŒ–ç‚¹å°†å…³èŠ‚é€Ÿåº¦è½¨è¿¹åˆ†å‰²ä¸ºä¸‰æ®µ
        
        å‚æ•°:
            jv: å…³èŠ‚é€Ÿåº¦æ•°ç»„ï¼Œå½¢çŠ¶ä¸º(n,6)çš„äºŒç»´æ•°ç»„
            gripper_data: å¤¹çˆªå®½åº¦æ•°æ®ï¼Œä¸€ç»´æ•°ç»„
            threshold: åˆ¤æ–­å¤¹çˆªå¼€åˆçš„é˜ˆå€¼
            
        è¿”å›:
            dict: åŒ…å«ä¸‰æ®µè½¨è¿¹çš„å­—å…¸ {
                'stage1': ç¬¬ä¸€é˜¶æ®µè½¨è¿¹,
                'stage2': ç¬¬äºŒé˜¶æ®µè½¨è¿¹,
                'stage3': ç¬¬ä¸‰é˜¶æ®µè½¨è¿¹,
                'change_points': å˜åŒ–ç‚¹ç´¢å¼•
            }
        """
        # ç¡®ä¿æœ‰ä¸¤ä¸ªå˜åŒ–ç‚¹
        if len(change_indices) != 2:
            raise ValueError(f"æœŸæœ›2ä¸ªå˜åŒ–ç‚¹,ä½†æ‰¾åˆ°{len(change_indices)}ä¸ª")
        
        # è·å–ä¸¤ä¸ªå˜åŒ–ç‚¹
        cp1, cp2 = change_indices
        
        # åˆ†å‰²è½¨è¿¹
        stage1 = jv[:cp1]      # ç¬¬ä¸€é˜¶æ®µï¼šä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªå˜åŒ–ç‚¹
        stage2 = jv[cp1:cp2]   # ç¬¬äºŒé˜¶æ®µï¼šç¬¬ä¸€ä¸ªå˜åŒ–ç‚¹åˆ°ç¬¬äºŒä¸ªå˜åŒ–ç‚¹
        stage3 = jv[cp2:]      # ç¬¬ä¸‰é˜¶æ®µï¼šç¬¬äºŒä¸ªå˜åŒ–ç‚¹åˆ°ç»“æŸ
        
        return stage1,stage2,stage3
    
    # -------------------------
    # ç”ŸæˆæŠ“å–å§¿æ€
    # -------------------------
    def create_grasps(self):
        if os.path.exists(GRASP_PATH_BLOCKS):
            return
        print("ğŸ§© ç”ŸæˆæŠ“å–å§¿æ€ä¸­...")
        obj = mcm.CollisionModel(BLOCK_MODEL_PATH)
 
        grasps = gpa.plan_gripper_grasps(
            self.gripper, obj,
            angle_between_contact_normals=rm.radians(175),
            rotation_interval=rm.radians(15),
            max_samples=20,
            min_dist_between_sampled_contact_points=0.03,
            contact_offset=0.01
        )
        grasps.save_to_disk(GRASP_PATH_BLOCKS)
        print(f"âœ… ä¿å­˜æŠ“å–å§¿æ€ï¼Œå…± {len(grasps)} ä¸ª")

    def _execute_trajectory(self, arm, mot_data, steps_per_segment=5):
        """
        åœ¨åŸ mot_data åŸºç¡€ä¸Šæ’å€¼æ‰§è¡Œï¼Œä½¿æœºæ¢°è‡‚è¿åŠ¨æ›´å¹³æ»‘
        :param steps_per_segment: æ¯ä¸¤å¸§ä¹‹é—´æ’å€¼æ­¥æ•°
 ``23       """
        jv_list = mot_data.jv_list
        ev_list = mot_data.ev_list

        for k in range(len(jv_list) - 1):
            start_j = np.array(jv_list[k])
            end_j = np.array(jv_list[k + 1])
            start_gripper = 0.07 if ev_list[k] >= 0.09 else 0.0
            end_gripper = 0.07 if ev_list[k + 1] >= 0.09 else 0.0

            for i in range(1, steps_per_segment + 1):
                alpha = i / steps_per_segment
                jv = start_j * (1 - alpha) + end_j * alpha
                gripper_angle = start_gripper * (1 - alpha) + end_gripper * alpha
                arm.move_m(jv, kp = 10, kd = 0.8,vel_ref = 5)
                arm.gripper_control(angle=gripper_angle)
                time.sleep(0.02)

        # æ‰§è¡Œæœ€åä¸€å¸§
        arm.move_j(jv_list[-1], speed=10)
        arm.gripper_control(angle=0.1 if ev_list[-1] >= 0.09 else 0.0)

 

    # -------------------------
    # æ‰§è¡Œ pick & place
    # -------------------------
    def execute_pick_place(self, start_pos, goal_pos, arm: PiperArmController, robot, obstacles, use_rrt:bool):
        print(f"ğŸ¤– ä» {start_pos} æŠ“å– â†’ æ”¾åˆ° {goal_pos}")
        cls_id, pos = start_pos
        block = mcm.CollisionModel(BLOCK_MODEL_PATH)
        block.pos = np.array(pos, dtype=float)
        goal_rot = rm.rotmat_from_euler(0, 0, 0)
        planner = ppp.PickPlacePlanner(robot)
        grasps = gg.GraspCollection.load_from_disk(GRASP_PATH_BLOCKS)

        mot_data = planner.gen_pick_and_place(
            obj_cmodel=block,
            end_jnt_values=robot.get_jnt_values(),
            grasp_collection=grasps,
            goal_pose_list=[(goal_pos, goal_rot)],
            pick_approach_direction=-rm.const.z_ax,
            place_approach_distance_list=[.05],
            place_depart_distance_list=[.05],
            pick_approach_distance=.05,
            pick_depart_distance=.05,
            obstacle_list=obstacles,
            use_rrt=use_rrt
        )
        if mot_data is None:
            print("âš ï¸ è½¨è¿¹è§„åˆ’å¤±è´¥ï¼")
            return False

        jv = mot_data.jv_list
        ev = mot_data.ev_list
        print(ev)
        binary_arr, change_indices = self.process_gripper_data(ev)
        print(change_indices)
        approach_path,pick_path,depart_path = self.split_trajectory_by_gripper(jv,change_indices)
        arm.open_gripper(width=0.08)
        arm.move_j(jv[0],speed=20,block=True)

        time.sleep(0.1)
        arm.move_jntspace_path(approach_path,speed=20)
        time.sleep(0.1)
        arm.close_gripper()
        time.sleep(0.1)
        arm.move_jntspace_path(pick_path,speed=20)
        time.sleep(0.1)
        arm.open_gripper(width = 0.08)
        time.sleep(1) 
        arm.move_jntspace_path(depart_path,speed=20)

        return mot_data
    # -------------------------
    # æœºæ¢°è‡‚é€‰æ‹©
    # -------------------------
    def choose_arm(self, block_pos):
        # block_pos æ˜¯ (cls_id, [x, y, z])
        _, pos = block_pos
        if pos[1] > -0.3:
            return self.left_arm, self.rbt_s.use_lft()
        else:
            return self.right_arm, self.rbt_s.use_rgt()

    # -------------------------
    # ä¸»ä»»åŠ¡å…¥å£
    # -------------------------
    def run(self, show_camera=False):
  
        obstacles = [
            mcm.gen_box(xyz_lengths=[0.8, 1.4, 1], pos=np.array([0.34, -0.2985, -0.5])),
            mcm.gen_box(xyz_lengths=[0.03, 0.03, 0.555], pos=np.array([-0.05, -0.2985, 0.2775])),
            mcm.gen_box(xyz_lengths=[0.08, 0.16, 0.14], pos=np.array([-0.03, -0.23, 0.07])),
            mcm.gen_box(xyz_lengths=[0.08, 0.16, 0.14], pos=np.array([-0.03, -0.375, 0.07]))
        ]


        self.create_grasps()
        self.left_arm.move_j([0] * 6, speed=20)
        self.right_arm.move_j([0] * 6, speed=20)

        # -------------------------
        # ç¬¬ä¸€æ­¥ï¼šæ£€æµ‹æ‰€æœ‰æ–¹å—
        # -------------------------
        blocks = self.detect_blocks(show=show_camera)
        if len(blocks) == 0:
            print("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•æ–¹å—ï¼")
            return False
        
        # -------------------------
        # ç¬¬äºŒæ­¥ï¼šæŒ‰é¢œè‰²åˆ†ç±»
        # -------------------------
        color_to_block = {0: None, 1: None, 2: None} # <--- ä¿®æ”¹ï¼šå°† 1,2,3 æ”¹ä¸º 0,1,2
        for cls_id, pos in blocks:
            color_to_block[cls_id] = (cls_id, pos)

        detected_colors = [k for k, v in color_to_block.items() if v is not None]
        if len(detected_colors) < 3:
            print(f"âš ï¸ æ£€æµ‹åˆ°çš„é¢œè‰²ä¸è¶³ä¸‰ä¸ªï¼Œä»…æ£€æµ‹åˆ° {detected_colors}")
            return False

        # -------------------------
        # ç¬¬ä¸‰æ­¥ï¼šæŒ‰é¢œè‰²é¡ºåºæ‰§è¡ŒæŠ“å–ä¸æ”¾ç½®
        # çº¢(0) â†’ ç»¿(1) â†’ è“(2)
        # -------------------------
        color_sequence = [0, 1, 2] # <--- ä¿®æ”¹ï¼šå°† 1,2,3 æ”¹ä¸º 0,1,2
        all_mot_data = []
        color_name_map = {0: "çº¢è‰²", 1: "ç»¿è‰²", 2: "è“è‰²"} # <--- ä¿®æ”¹ï¼šå°† 1,2,3 æ”¹ä¸º 0,1,2

        use_rrt = False
        for i, color_id in enumerate(color_sequence):

            #æœ€åä¸€ä¸ªæ–¹å—æ·»åŠ éšœç¢,å¹¶ä¸”å¯ç”¨rrt
            if i == 2:
                #æ·»åŠ éšœç¢
                obstacles.append(mcm.gen_box(xyz_lengths=[0.05, 0.05, 0.10], pos=np.array([0.25, -0.3, 0])))
                use_rrt = False
            block = color_to_block[color_id]
            target = TARGET_POSITIONS[i]
            color_name = color_name_map[color_id]

            print(f"\n=== å¼€å§‹æŠ“å–ç¬¬ {i + 1} ä¸ªæ–¹å—ï¼š{color_name} ===")

            # åˆ¤æ–­ä½¿ç”¨å“ªåªæ‰‹
            arm, robot = self.choose_arm(block)
            arm_name = "å·¦è‡‚" if arm is self.left_arm else "å³è‡‚"
            print(f"ğŸ‘‰ ä½¿ç”¨ {arm_name} æŠ“å– {color_name} æ–¹å—")

            # --- ä¿®æ”¹ z åæ ‡ä¸º 0ï¼Œç”¨äºæŠ“å– ---
            block_for_pick = (block[0], block[1].copy())  # å…ˆå¤åˆ¶åŸå§‹åæ ‡
            block_for_pick[1][2] = 0.0  # å¼ºåˆ¶ z = 0

            mot_data = self.execute_pick_place(block_for_pick, target, arm, robot, obstacles, use_rrt)

            if mot_data is None:
                print(f"âŒ {color_name} æ–¹å—å †å å¤±è´¥")
                continue

            print(f"âœ… {color_name} æ–¹å—å †å æˆåŠŸï¼ˆç”± {arm_name} å®Œæˆï¼‰")
        

 
        return True


# ==================================
# main
# ==================================
def main():
    task = MultiCameraBlockTask()
    try:
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)
        start_time = time.time()
        success = task.run(show_camera=False)
        end_time = time.time()
        print(f"æ¨ç†æ—¶é—´:{start_time -  end_time}")
        print("ä»»åŠ¡æˆåŠŸ âœ…" if success else "ä»»åŠ¡å¤±è´¥ âŒ")
    except KeyboardInterrupt:
        print("\nâš ï¸ æ•è·åˆ° Ctrl+Cï¼Œæœºæ¢°è‡‚å›åˆ°å…¨é›¶ä½...")
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)
    except Exception as e:
        import traceback
        traceback.print_exc()
        print("âš ï¸ å‡ºç°å¼‚å¸¸ï¼Œæœºæ¢°è‡‚å›åˆ°å…¨é›¶ä½...")
        task.left_arm.move_j([0]*6, speed=20)
        task.right_arm.move_j([0]*6, speed=20)

if __name__ == '__main__':
    main()